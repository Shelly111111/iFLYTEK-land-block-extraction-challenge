{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# iFLYTEK 长光卫星——[高分辨率遥感影像耕地地块提取挑战赛](http://challenge.xfyun.cn/topic/info?type=plot-extraction-2021)（非官方baseline）\n",
    "**<font color=red>注意：本项目不提供赛题数据集，若训练，可通过上方链接从官网报名下载数据集</font>**\n",
    "\n",
    "## 一、赛事背景\n",
    "耕地的数量和质量是保证我国农业可持续发展的关键。遥感技术可以准确、及时地探测地表信息，客观地反映地物的状态及其变化。利用高分辨率遥感影像准确地提取耕地地块是精准农业的基本任务。目前提取高精度的耕地地块产品主要还是依靠人工解译的手段，费时费力。传统耕地地块提取技术的效率已无法满足当前精细化农业应用快速响应的需求。高分辨率遥感影像耕地地块的自动化提取算法依然是国内外遥感领域共同面临的科学问题。因此，本赛道旨在充分利用遥感大数据、人工智能等先进技术，实现高效、可用、实用的先进算法，以提升自动化提取高分辨率遥感影像中耕地地块的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、赛事任务\n",
    "我国幅员辽阔，由于自然地理环境差异较大，耕地类型因地而异，精细农业需要强大的数据作为支撑，本次大赛以吉林一号高分辨率卫星遥感影像作为数据集，参赛选手需基于提供的样本构建模型，预测未知影像中耕地的矢量边界范围。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、数据说明\n",
    "本次大赛提供吉林一号高分辨率遥感影像作为数据源，影像为四通道数据（B,G,R,NIR），分辨率为0.75~1.1米之间。包括训练数据与测试数据，由长光卫星技术有限公司拍摄、标注、构建。其中，初赛数据集包括16张不同尺寸的tif图片。\n",
    "\n",
    "a. 原始影像\n",
    "\n",
    "影像格式为tif，包含B、G、R、NIR四个波段，训练集影像为一系列尺寸不固定的遥感影像（行数与列数≥3000），用于初赛与复赛的测试集影像尺寸可变。\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/a4c3288b3e9b4d2f8fcde2e89d60315de6d9fa830d32460492dee3b39cec83d8\" width=400/>\n",
    "\n",
    "\n",
    "b.\t标签数据\n",
    "\n",
    "标签格式为矢量数据（shapefile），标签数据的名称与原始影像一致。标签数据中的特征类型为多边形即耕地地块范围以多边形方式进行勾画\n",
    "\n",
    "出于数据安全保证的考虑，所有数据均为脱敏处理后的数据，地理坐标加偏移。 此次比赛分为初赛和复赛两个阶段，两个阶段的区别是所提供的测试数据不同，其他的设置均相同。\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/6255349b2d634013b1cfcc19e1d9dff20d3d40ea2fd54a9796962faf0e0e4d5d\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、比赛思路\n",
    "\n",
    "### 1.文件格式转化\n",
    "该比赛任务明显为语义分割，需要将地图数据划分为`0：背景`以及`1：耕地`这两种类别，可以使用`PaddleSeg`来完成。首先将tif图转化为png图以适配`PaddleSeg`，并需要将shp文件转化为png或jpg格式的图片标注文件。\n",
    "\n",
    "<font color=red>注：由于本作者还未找到在AI Studio中安装GDAL库的方案，所以该代码只能在装有python第三方库GDAL的本地运行。</font>\n",
    "\n",
    "tif转png示例代码：\n",
    "\n",
    "```\n",
    "from PIL import  Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "im = Image.open('JPEGImages/CGSH_1_offset.tif').convert('RGBA')\n",
    "im.save('JPEGImages/CGSH_1_offset.png')\n",
    "```\n",
    "\n",
    "shp文件转化png示例代码：\n",
    "\n",
    "```\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "ROOT = r'F:/ChangguangSatellite_Coffe'\n",
    "img_path = 'JPEGImages'\n",
    "shp_path = 'Annotations'\n",
    "# root path for saving the mask.\n",
    "ROOT_DIR = ROOT + '/train'\n",
    "IMAGE_DIR = ROOT_DIR+\"/\"+img_path\n",
    "ANNOTATION_DIR = ROOT_DIR+'/'+shp_path\n",
    "\n",
    "\n",
    "def filter_for_annotations(root, files):\n",
    "    file_types = ['*.shp']\n",
    "    file_types = r'|'.join([fnmatch.translate(x) for x in file_types])\n",
    "    files = [os.path.join(root, f) for f in files]\n",
    "    files = [f for f in files if re.match(file_types, f)]\n",
    "    return files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(os.path.join(ROOT_DIR,'train.txt'),'w',encoding='utf-8') as fp:\n",
    "        for root, _, files in os.walk(ANNOTATION_DIR):\n",
    "            annotation_files = filter_for_annotations(ANNOTATION_DIR, files)\n",
    "            for segpath in annotation_files:\n",
    "                result = gdal.Warp('masked.png'\n",
    "                   , os.path.join(IMAGE_DIR, os.path.splitext(os.path.basename(segpath))[0])+'.tif'\n",
    "                   , cutlineDSName=os.path.join(ANNOTATION_DIR, os.path.splitext(os.path.basename(segpath))[0])+'.shp')\n",
    "                arr=result.ReadAsArray()[0]\n",
    "                arr[arr>0]=1 #这里将数组中大于0的数据全部标为1\n",
    "                im = Image.fromarray(arr).convert('L')\n",
    "                im.save(os.path.join(ANNOTATION_DIR, os.path.splitext(os.path.basename(segpath))[0])+'.png')\n",
    "                del result\n",
    "                fp.write(img_path+'/'+os.path.splitext(os.path.basename(segpath))[0]+'.png '+\n",
    "                         shp_path+'/'+os.path.splitext(os.path.basename(segpath))[0]+'.png\\n')\n",
    "                print(ANNOTATION_DIR+'/'+os.path.splitext(os.path.basename(segpath))[0]+'.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "将生成的图片文件以及标注文件打包上传到AI Studio上，解压缩并将文件命名如下：\n",
    "\n",
    "- labels.txt\t(标签类别，由于是二分类，所以只需要输入如：plough一行即可)\n",
    "- train.txt\t\t（训练集，每行都包含训练的图片路径以及对应的标注路径，并使用空格进行分割）\n",
    "- val.txt\t\t（验证集，每行都包含验证的图片路径以及对应的标注路径，并使用空格进行分割）\n",
    "- test.txt\t\t（测试集，每行都包含测试的图片路径）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.数据集增强\n",
    "\n",
    "这里手动进行了一下数据集的增强，使用`PIL.ImageEnhance`对图片进行色度、对比度、亮度以及清晰度的扩增。使用扩增后的数据集进行训练，准确率提升约3个百分点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "from PIL import Image,ImageEnhance\r\n",
    "Image.MAX_IMAGE_PIXELS = None\r\n",
    "\r\n",
    "color_aug=[0.1,0.2,0.3]\r\n",
    "bright_aug=[0.5,2.0]\r\n",
    "contrast_aug=[0.5,2.0]\r\n",
    "sharp_aug=[0.0,0.5,2.0,4.0]\r\n",
    "\r\n",
    "def enhance(line,fr,fw):\r\n",
    "    fw.write(line)\r\n",
    "    img_path = line.strip().split(' ')[0]\r\n",
    "    ann_path = line.strip().split(' ')[1]\r\n",
    "    img = Image.open(img_path)\r\n",
    "    for i,rate in enumerate(color_aug):\r\n",
    "        aug_img = ImageEnhance.Color(img).enhance(rate)\r\n",
    "        aug_img.save(img_path.split('.')[0]+'_c{}.png'.format(i+1))\r\n",
    "        fw.write(img_path.split('.')[0]+'_c{}.png'.format(i+1)+ ' ' + ann_path+'\\n')\r\n",
    "    for i,rate in enumerate(bright_aug):\r\n",
    "        aug_img = ImageEnhance.Brightness(img).enhance(rate)\r\n",
    "        aug_img.save(img_path.split('.')[0]+'_b{}.png'.format(i+1))\r\n",
    "        fw.write(img_path.split('.')[0]+'_b{}.png'.format(i+1)+ ' ' + ann_path+'\\n')\r\n",
    "    for i,rate in enumerate(contrast_aug):\r\n",
    "        aug_img = ImageEnhance.Contrast(img).enhance(rate)\r\n",
    "        aug_img.save(img_path.split('.')[0]+'_ct{}.png'.format(i+1))\r\n",
    "        fw.write(img_path.split('.')[0]+'_ct{}.png'.format(i+1)+ ' ' + ann_path+'\\n')\r\n",
    "    for i,rate in enumerate(sharp_aug):\r\n",
    "        aug_img = ImageEnhance.Sharpness(img).enhance(rate)\r\n",
    "        aug_img.save(img_path.split('.')[0]+'_s{}.png'.format(i+1))\r\n",
    "        fw.write(img_path.split('.')[0]+'_s{}.png'.format(i+1)+ ' ' + ann_path+'\\n')\r\n",
    "\r\n",
    "with open('train.txt','r',encoding='utf-8') as fr:\r\n",
    "    with open('enhance_train.txt','w',encoding='utf-8') as fw:\r\n",
    "        lines = fr.readlines()\r\n",
    "        for line in lines:\r\n",
    "            enhance(line,fr,fw)\r\n",
    "\r\n",
    "with open('val.txt','r',encoding='utf-8') as fr:\r\n",
    "    with open('enhance_val.txt','w',encoding='utf-8') as fw:\r\n",
    "        lines = fr.readlines()\r\n",
    "        for line in lines:\r\n",
    "            enhance(line,fr,fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、使用PaddleSeg进行模型训练\n",
    "\n",
    "PaddleSeg详细使用指南见：[PaddleSeg官方文档](https://paddleseg.readthedocs.io/zh_CN/release-2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#下载所需的包\r\n",
    "!pip install scikit-image\r\n",
    "!pip install geopandas\r\n",
    "!pip install shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.使用ocrnet_hrnetw48_voc12aug_512x512_40k.yml进行训练\n",
    "\n",
    "**<font size=3>（1）ocrnet</font>**\n",
    "\n",
    "Paper：[Segmentation Transformer: Object-Contextual\n",
    "Representations for Semantic Segmentation](https://arxiv.org/pdf/1909.11065.pdf)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/18f4a49387604fc9b936bf820b84a591d264c71853f245c8b99a7277630bd210)\n",
    "\n",
    "<font size=3>ocrnet提出了使用Transformer编码器-解码器框架重新表述对象上下文的方案。\n",
    "  \n",
    "  在解码器中，前两步即目标区域学习和目标区域表示计算被集成为交叉注意模块：用于对像素进行分类的线性投影（即生成目标区域）是类别查询，目标区域表示是交叉注意输出。\n",
    "  \n",
    "  最后一步是添加到编码器的交叉注意模块，其中键和值是解码器输出，查询是每个位置的表示。</font>\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/be251f34521d4ea4b1b7a48dc62a31c4779b33c2c0804d2cb16d087937c9fd70\" width=1000/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**<font size=3>（2）对配置文件进行修改</font>**\n",
    "\n",
    "配置文件说明可见：[配置项](https://paddleseg.readthedocs.io/zh_CN/release-2.1/design/use/use.html)\n",
    "  \n",
    "<font color=red>注意：这里要使用RandomPaddingCrop对图片进行训练时增强</font>\n",
    "|ocrnet_hrnetw18_voc12aug_512x512_40k.yml|cityscapes.yml|\n",
    "|---|---|\n",
    "|![ocrnet_hrnetw18_voc12aug_512x512_40k.yml](https://ai-studio-static-online.cdn.bcebos.com/b90708b990e6461a8be6955410babc1fab071ec41b3948e28a452e299d569f10)|![cityscapes.yml](https://ai-studio-static-online.cdn.bcebos.com/65cf11c6416240809cc9abe661f4ebdfd5765c7be9d84d9d9382decd435bfc82)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "（3）模型训练\n",
    "\n",
    "模型训练配置见：[模型训练](https://paddleseg.readthedocs.io/zh_CN/release-2.1/train/train.html)\n",
    "\n",
    "<font color=red>注意：方案中在进行图片验证时，首先将图片动态切割为多个较小的图片，然后一一进行预测，最终将预测图拼接成一张总的预测图片，修改代码见`PaddleSeg/paddleseg/core/val.py`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python PaddleSeg/train.py --config PaddleSeg/configs/ocrnet/ocrnet_hrnetw48_voc12aug_512x512_40k.yml \\\r\n",
    "        --iters 19200 \\\r\n",
    "        --learning_rate 0.0125 \\\r\n",
    "        --save_interval 192 \\\r\n",
    "        --do_eval \\\r\n",
    "        #--resume_model 'output/ocr_best_14592'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#删除多余的训练模型\r\n",
    "!rm -rf ./output/iter*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=3>这里除ocrnet外，还提供了其他几个模型，有兴趣可以将ocrnet替换为下列模型</font>\n",
    "> deeplabv3/deeplabv3_resnet50_os8_voc12aug_512x512_40k.yml\n",
    "\n",
    "> deeplabv3/deeplabv3_resnet101_os8_voc12aug_512x512_40k.yml\n",
    "\n",
    "> deeplabv3p/deeplabv3p_resnet50_os8_voc12aug_512x512_40k.yml\n",
    "\n",
    "> deeplabv3p/deeplabv3p_resnet101_os8_voc12aug_512x512_40k.yml\n",
    "\n",
    "> ocrnet/ocrnet_hrnetw48_voc12aug_512x512_40k.yml\n",
    "\n",
    "> ocrnet/ocrnet_hrnetw18_voc12aug_512x512_40k.yml\n",
    "\n",
    "> fcn/fcn_hrnetw18_voc12aug_512x512_40k.yml\n",
    "\n",
    "> fcn/fcn_hrnetw48_voc12aug_512x512_40k.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、模型预测\n",
    "\n",
    "<font color=red>**注意：**\n",
    "  \n",
    "  1.由于本作者还未找到在AI Studio中安装GDAL库的方案，所以预测代码只能在装有python第三方库GDAL的本地运行。</font>\n",
    "\n",
    "  <font color=red>2.方案中在进行图片预测时，同样首先将图片动态切割为多个较小的图片，然后一一进行预测，最终将预测图拼接成一张总的预测图片，修改代码见`PaddleSeg\\paddleseg\\core\\predict.py`。</font>此外，该文件中设置了形态学中的开运算。由于获取每个预测多边形时，可能会存在将预测多边形包含于其他多边形内部的情况，针对这种情况代码进行了两种处理方式：**将包含于内部的小多边形视为孔洞进行去除**以及**忽视包含于内部的小多边形**，通过设置参数`cut_hole`来进行选择。\n",
    "  \n",
    "3.shp文件生成代码见`PaddleSeg\\Shp_data_out.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd PaddleSeg\r\n",
    "#该代码同PaddleSeg/test.py\r\n",
    "import os\r\n",
    "import paddleseg\r\n",
    "from paddleseg.models import U2Net,DeepLabV3,FCN,OCRNet\r\n",
    "from paddleseg.models.backbones.resnet_vd import ResNet50_vd\r\n",
    "from paddleseg.models.backbones.hrnet import HRNet_W18,HRNet_W48\r\n",
    "\r\n",
    "Root = '/home/aistudio'\r\n",
    "image_dir=os.path.join(Root,'test')\r\n",
    "\r\n",
    "#backbone= ResNet50_vd()\r\n",
    "backbone= HRNet_W48()\r\n",
    "\r\n",
    "model = OCRNet(\r\n",
    "    backbone=backbone,\r\n",
    "    backbone_indices=[0],\r\n",
    "    num_classes=2,\r\n",
    ")\r\n",
    "\r\n",
    "model_path = os.path.join(Root,'output/ocr_best_10752/model.pdparams') #最优模型路径\r\n",
    "\r\n",
    "# 构建验证用的transforms\r\n",
    "import paddleseg.transforms.transforms as T\r\n",
    "transforms = T.Compose([\r\n",
    "    T.Normalize()\r\n",
    "])\r\n",
    "\r\n",
    "with open(os.path.join(image_dir,'test.txt'),'r',encoding='utf-8') as fp:\r\n",
    "    lines=fp.readlines()\r\n",
    "    image_list=[os.path.join(image_dir,line.strip()) for line in lines]\r\n",
    "\r\n",
    "paddleseg.core.predict(\r\n",
    "                    model,\r\n",
    "                    model_path,\r\n",
    "                    transforms,\r\n",
    "                    image_list = image_list,\r\n",
    "                    image_dir=image_dir,\r\n",
    "                    save_dir=os.path.join(Root, 'output/predict'),\r\n",
    "                    aug_pred=False,\r\n",
    "                    scales=1.0,\r\n",
    "                    flip_horizontal=False,\r\n",
    "                    flip_vertical=False,\r\n",
    "                    is_slide=False,\r\n",
    "                    stride=None,\r\n",
    "                    shape=(512,512),\r\n",
    "                    kernel_size=(10,10),#开运算核\r\n",
    "                    MORPH_OPEN=True,#是否执行开运算\r\n",
    "                    MORPH_OPEN_NUM = 3,#执行开运算次数\r\n",
    "                    cut_hole = True,#是否去掉预测多边形中的孔洞\r\n",
    "                    crop_size=None\r\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、效果展示\n",
    "\n",
    "\n",
    "\n",
    "| 原图 | 预测图 | shp文件可视化 |\n",
    "| -------- | -------- | -------- |\n",
    "| ![](https://ai-studio-static-online.cdn.bcebos.com/fba4dd5765fe410cb928a43e239005b7b7047e8518ee4556a4a0ccfe90f598ee) | ![](https://ai-studio-static-online.cdn.bcebos.com/088de4ea73d841c696239faece4b86b3882494b75acc438da8ac048fd2709a08) | ![](https://ai-studio-static-online.cdn.bcebos.com/3ff785fc7ddc4a6d940f2c5a8e6f128f433822f21c0e4bd680a0f85648a99bc5)  |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 八、总结\n",
    "\n",
    "比赛图片实在太大，即使是32G显存的AI Studio训练也还是十分吃紧，此外，训练结果不算太理想，miou在32上，与前排大佬还是有很大差距，希望有大佬能够点出不足。\n",
    "\n",
    ">本人武汉科技大学信息安全专业毕业，今年考入本校研究生，在CV和NLP上都有兴趣~\n",
    "\n",
    ">我在AI Studio上获得钻石等级，点亮8个徽章\n",
    "\n",
    ">欢迎关注[我的主页](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/71231)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
